{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkgkMwgUAqp/Tj9daCV6/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ndthain25092002/Intent-detection-and-slot-filling/blob/main/ID_SF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N06s9joEZtkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89dbe11-b6a2-4477-a880-d028db02d929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "from torchtext import data, datasets\n",
        "import pickle\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import csv"
      ],
      "metadata": {
        "id": "ZUopSFt3aEqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sử dụng hàm lambda để định nghĩa phương thức tách từ đơn giản, ở đây là tách theo khoảng trắng\n",
        "tokenize = lambda s: s.split()\n",
        "\n",
        "# Định nghĩa trường TEXT (dùng để xử lý văn bản)\n",
        "TEXT = data.Field(\n",
        "    sequential=True,         # Dữ liệu là chuỗi văn bản\n",
        "    tokenize=tokenize,       # Phương thức tách từ sử dụng hàm lambda trên\n",
        "    lower=True,               # Chuyển đổi văn bản thành chữ thường\n",
        "    use_vocab=True,           # Sử dụng từ điển\n",
        "    init_token='<sos>',       # Thêm token bắt đầu chuỗi\n",
        "    eos_token='<eos>',        # Thêm token kết thúc chuỗi\n",
        "    pad_token='<pad>',        # Thêm token dùng để đệm độ dài câu\n",
        "    unk_token='<unk>',        # Thêm token cho từ không xác định\n",
        "    batch_first=True,         # Batch đầu tiên trong tensor có kích thước (batch_size, seq_len, ...)\n",
        "    fix_length=50,            # Đặt độ dài cố định cho mỗi chuỗi\n",
        "    include_lengths=True      # Bao gồm thông tin chiều dài của mỗi chuỗi trong kết quả\n",
        ")\n",
        "\n",
        "# Định nghĩa trường SLOT (tương tự như TEXT)\n",
        "SLOT = data.Field(\n",
        "    sequential=True,\n",
        "    tokenize=tokenize,\n",
        "    lower=True,\n",
        "    use_vocab=True,\n",
        "    init_token='<sos>',\n",
        "    eos_token='<eos>',\n",
        "    pad_token='<pad>',\n",
        "    unk_token='<unk>',\n",
        "    batch_first=True,\n",
        "    fix_length=50,\n",
        "    include_lengths=True\n",
        ")\n",
        "\n",
        "# Định nghĩa trường INTENT (tương tự như TEXT, nhưng không phải là chuỗi mà là một giá trị duy nhất)\n",
        "INTENT = data.Field(\n",
        "    sequential=False,  # Không phải là chuỗi\n",
        "    use_vocab=True\n",
        ")\n",
        "\n",
        "# Tạo tập dữ liệu huấn luyện và tập dữ liệu validation từ các file CSV\n",
        "train, val = data.TabularDataset.splits(\n",
        "    path='./',\n",
        "    skip_header=True,\n",
        "    train='train.csv',\n",
        "    validation='val.csv',\n",
        "    format='csv',\n",
        "    fields=[('text', TEXT), ('slot', SLOT), ('intent', INTENT)]\n",
        ")\n",
        "\n",
        "# Xây dựng từ điển từ vựng cho TEXT, SLOT và INTENT từ tập dữ liệu huấn luyện và validation\n",
        "TEXT.build_vocab(train, val)\n",
        "SLOT.build_vocab(train, val)\n",
        "INTENT.build_vocab(train, val)\n",
        "\n",
        "# Tạo các iterators cho tập huấn luyện và tập validation\n",
        "train_iter, val_iter = data.Iterator.splits(\n",
        "    (train, val),\n",
        "    batch_sizes=(32, len(val)),\n",
        "    shuffle=True,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.text)\n",
        ")\n",
        "\n",
        "# Tạo tập dữ liệu kiểm tra từ file CSV\n",
        "test = data.TabularDataset(\n",
        "    path='test.csv',\n",
        "    format='csv',\n",
        "    fields=[('text', TEXT), ('slot', SLOT), ('intent', INTENT)],\n",
        "    skip_header=True\n",
        ")\n",
        "\n",
        "# Tạo iterator cho tập dữ liệu kiểm tra\n",
        "test_iter = data.Iterator(\n",
        "    test,\n",
        "    batch_size=len(test),\n",
        "    shuffle=True,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.text)\n",
        ")\n"
      ],
      "metadata": {
        "id": "pj08x4yybAnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save text\n",
        "text_words_path = os.path.join(os.getcwd(), 'text_words.pkl')\n",
        "with open(text_words_path, 'wb') as f_text_words:\n",
        "    pickle.dump(TEXT.vocab, f_text_words)\n",
        "\n",
        "# save slot\n",
        "slot_words_path = os.path.join(os.getcwd(), 'slot_words.pkl')\n",
        "with open(slot_words_path, 'wb') as f_slot_words:\n",
        "    pickle.dump(SLOT.vocab, f_slot_words)\n",
        "\n",
        "# save intent\n",
        "intent_words_path = os.path.join(os.getcwd(), 'intent_words.pkl')\n",
        "with open(intent_words_path, 'wb') as f_intent_words:\n",
        "    pickle.dump(INTENT.vocab, f_intent_words)\n",
        "\n",
        "TEXT.vocab.stoi[TEXT.pad_token]\n"
      ],
      "metadata": {
        "id": "T5Zwv_VbdJot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19716b2f-3655-4d82-9954-685f4cc958e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "8PCdhgO5AHjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Định nghĩa một mô hình PyTorch Module cho SlotGate\n",
        "class SlotGate(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(SlotGate, self).__init__()\n",
        "        # Tạo các lớp tuyến tính cho SlotGate\n",
        "        self.fc_intent_context = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, slot_context, intent_context):\n",
        "        # Tuyến tính hóa intent_context\n",
        "        intent_context_linear = self.fc_intent_context(intent_context)\n",
        "\n",
        "        # Tổng của slot_context và intent_context sau khi được biến đổi tuyến tính\n",
        "        sum_intent_slot_context = slot_context + intent_context_linear\n",
        "\n",
        "        # Hàm kích hoạt tanh theo phần tử sau đó làm biến đổi tuyến tính khác\n",
        "        fc_linear = self.fc_v(torch.tanh(sum_intent_slot_context))\n",
        "\n",
        "        # Tính tổng theo chiều của chuỗi\n",
        "        sum_gate_vec = torch.sum(fc_linear, dim=1)\n",
        "        return sum_gate_vec\n",
        "\n",
        "# Định nghĩa một mô hình PyTorch Module cho AttnContext\n",
        "class AttnContext(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(AttnContext, self).__init__()\n",
        "\n",
        "    def forward(self, hidden, text_output_hidden):\n",
        "        # Thêm chiều của chuỗi cho 'hidden'\n",
        "        hidden = hidden.unsqueeze(1)\n",
        "\n",
        "        # Tính trọng số chú ý dựa trên tích phần tử\n",
        "        attn_weight = torch.sum(hidden * text_output_hidden, dim=2)\n",
        "\n",
        "        # Áp dụng softmax theo chiều của chuỗi\n",
        "        attn_weight = F.softmax(attn_weight, dim=1).unsqueeze(1)\n",
        "\n",
        "        # Thực hiện tổng có trọng số của chú ý\n",
        "        attn_vector = attn_weight.bmm(text_output_hidden)\n",
        "\n",
        "        # Squeeze chiều của chuỗi\n",
        "        return attn_vector.squeeze(1)"
      ],
      "metadata": {
        "id": "CMUbZxmDdJrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Định nghĩa một mô hình PyTorch Module cho Bi-directional LSTM với Attention và SlotGate\n",
        "class BirnnAttentionGate(nn.Module):\n",
        "    def __init__(self, text_input_dim, text_emb_dim, hidden_dim, n_layers, dropout, pad_index, slot_output_size, intent_output_size, seq_len, predict_flag, slot_attention_flag):\n",
        "        super(BirnnAttentionGate, self).__init__()\n",
        "\n",
        "        # Các tham số của mô hình\n",
        "        self.pad_index = pad_index\n",
        "        self.hidden_dim = hidden_dim // 2  # Vì sử dụng LSTM bidirectional\n",
        "        self.n_layers = n_layers\n",
        "        self.slot_output_size = slot_output_size\n",
        "        self.predict_flag = predict_flag\n",
        "        self.slot_attention_flag = slot_attention_flag\n",
        "\n",
        "        # Embedding layer cho văn bản đầu vào\n",
        "        self.text_embedding = nn.Embedding(text_input_dim, text_emb_dim, padding_idx=pad_index)\n",
        "\n",
        "        # LSTM bidirectional cho việc biểu diễn văn bản\n",
        "        self.text_lstm = nn.LSTM(text_emb_dim, self.hidden_dim, n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
        "\n",
        "        # Các thành phần cho Attention và SlotGate\n",
        "        self.slot_context = AttnContext(hidden_dim)\n",
        "        self.intent_context = AttnContext(hidden_dim)\n",
        "        self.slotGate = SlotGate(hidden_dim)\n",
        "\n",
        "        # Linear layers cho đầu ra dự đoán\n",
        "        self.intent_output = nn.Linear(hidden_dim, intent_output_size)\n",
        "        self.slot_output = nn.Linear(hidden_dim, slot_output_size)\n",
        "\n",
        "    def forward(self, text_input, text_len):\n",
        "        # Kiểm tra xem đang trong quá trình dự đoán hay không\n",
        "        if self.predict_flag:\n",
        "            assert len(text_input) == 1, 'Predicting one sentence at a time'\n",
        "            seq_len = text_len[0]\n",
        "\n",
        "            # Embedding văn bản đầu vào\n",
        "            text_embedded = self.text_embedding(text_input)\n",
        "\n",
        "            # Pack và unpack văn bản sử dụng PackedSequence để xử lý với độ dài biến đổi\n",
        "            packed = torch.nn.utils.rnn.pack_padded_sequence(text_embedded, text_len, batch_first=True, enforce_sorted=True)\n",
        "            text_output, (hidden, cell) = self.text_lstm(packed)\n",
        "            text_output, _ = torch.nn.utils.rnn.pad_packed_sequence(text_output, batch_first=True, padding_value=self.pad_index, total_length=len(text_input[0]))\n",
        "\n",
        "            # Khởi tạo tensor đầu ra cho slot predictions\n",
        "            batch_size = text_input.shape[0]\n",
        "            seq_len = text_input.shape[1]\n",
        "            slot_outputs = torch.zeros(batch_size, seq_len, self.slot_output_size).to(device)\n",
        "            aligns = text_output.transpose(0, 1)\n",
        "\n",
        "            # Lặp qua từng thời điểm trong chuỗi\n",
        "            for t in range(seq_len):\n",
        "                aligned = aligns[t]\n",
        "\n",
        "                # Tính toán slot context và intent context\n",
        "                if self.slot_attention_flag:\n",
        "                    slot_context = self.slot_context(aligned, text_output)\n",
        "                    intent_context = self.intent_context(text_output[:, -1, :], text_output)\n",
        "                    slot_gate = self.slotGate(slot_context, intent_context)\n",
        "                    slot_gate = slot_gate.unsqueeze(1)\n",
        "                    slot_context_gate = slot_gate * slot_context\n",
        "                else:\n",
        "                    intent_context = self.intent_context(text_output[:, -1, :], text_output)\n",
        "                    slot_gate = self.slotGate(text_output[:, t, :], intent_context)\n",
        "                    slot_gate = slot_gate.unsqueeze(1)\n",
        "                    slot_context_gate = slot_gate * text_output[:, t, :]\n",
        "\n",
        "                # Dự đoán slot và lưu vào tensor đầu ra\n",
        "                slot_prediction = self.slot_output(slot_context_gate + text_output[:, t, :])\n",
        "                slot_outputs[:, t, :] = slot_prediction\n",
        "\n",
        "            # Dự đoán intent từ context cuối cùng\n",
        "            intent_outputs = self.intent_output(intent_context + text_output[:, -1, :])\n",
        "\n",
        "            return slot_outputs, intent_outputs\n",
        "\n",
        "        else:\n",
        "            # Đoạn code tương tự như ở trên, nhưng không có quá trình dự đoán\n",
        "            text_embedded = self.text_embedding(text_input)\n",
        "            packed = torch.nn.utils.rnn.pack_padded_sequence(text_embedded, text_len, batch_first=True, enforce_sorted=True)\n",
        "            text_output, (hidden, cell) = self.text_lstm(packed)\n",
        "            text_output, _ = torch.nn.utils.rnn.pad_packed_sequence(text_output, batch_first=True, padding_value=self.pad_index, total_length=len(text_input[0]))\n",
        "\n",
        "            batch_size = text_input.shape[0]\n",
        "            seq_len = text_input.shape[1]\n",
        "            slot_outputs = torch.zeros(batch_size, seq_len, self.slot_output_size).to(device)\n",
        "            aligns = text_output.transpose(0, 1)\n",
        "\n",
        "            for t in range(seq_len):\n",
        "                aligned = aligns[t]\n",
        "\n",
        "                if self.slot_attention_flag:\n",
        "                    slot_context = self.slot_context(aligned, text_output)\n",
        "                    intent_context = self.intent_context(text_output[:, -1, :], text_output)\n",
        "                    slot_gate = self.slotGate(slot_context, intent_context)\n",
        "                    slot_gate = slot_gate.unsqueeze(1)\n",
        "                    slot_context_gate = slot_gate * slot_context\n",
        "                else:\n",
        "                    intent_context = self.intent_context(text_output[:, -1, :], text_output)\n",
        "                    slot_gate = self.slotGate(text_output[:, t, :], intent_context)\n",
        "                    slot_gate = slot_gate.unsqueeze(1)\n",
        "                    slot_context_gate = slot_gate * text_output[:, t, :]\n",
        "\n",
        "                slot_prediction = self.slot_output(slot_context_gate + text_output[:, t, :])\n",
        "                slot_outputs[:, t, :] = slot_prediction\n",
        "\n",
        "            intent_outputs = self.intent_output(intent_context + text_output[:, -1, :])\n",
        "\n",
        "            return slot_outputs, intent_outputs"
      ],
      "metadata": {
        "id": "Tss4OW9GdTrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(text, slot, intent, text_emb_dim, hidden_dim, n_layers, dropout, lr, gamma, weight_decay, seq_len):\n",
        "\n",
        "    # Xác định kích thước đầu vào, đầu ra và số lớp nhãn\n",
        "    input_dim = len(text.vocab)\n",
        "    output_dim = len(slot.vocab)\n",
        "    label_dim = len(intent.vocab)\n",
        "\n",
        "    # Xây dựng mô hình BirnnAttentionGate\n",
        "    model = BirnnAttentionGate(input_dim, text_emb_dim, hidden_dim, n_layers, dropout, text.vocab.stoi[text.pad_token], output_dim, label_dim, seq_len, False, True).to(device)\n",
        "\n",
        "    # Áp dụng hàm khởi tạo trọng số cho mô hình\n",
        "    model.apply(init_weights)\n",
        "\n",
        "    # Tạo optimizer Adam để tối ưu hóa trọng số của mô hình\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Tạo lên lịch giảm tốc độ học\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=2, verbose=False)\n",
        "\n",
        "    # Xác định chỉ số của ký tự đặc biệt \"pad\" để được sử dụng trong hàm CrossEntropyLoss\n",
        "    slot_pad_index = slot.vocab.stoi[text.pad_token]\n",
        "\n",
        "    # Hàm mất mát cho slot và intent\n",
        "    loss_slot = nn.CrossEntropyLoss(ignore_index=slot_pad_index)\n",
        "    loss_intent = nn.CrossEntropyLoss()\n",
        "\n",
        "    return model, optimizer, scheduler, loss_slot, loss_intent\n"
      ],
      "metadata": {
        "id": "Muv9ASEFdTzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, loss_slot, loss_intent, clip):\n",
        "    # Chuyển mô hình sang chế độ huấn luyện\n",
        "    model.train()\n",
        "\n",
        "    # Khởi tạo các biến tổng lỗi\n",
        "    epoch_loss = 0\n",
        "    slot_epoch_loss = 0\n",
        "    intent_epoch_loss = 0\n",
        "\n",
        "    # Lặp qua từng batch trong iterator\n",
        "    for i, batch in enumerate(iterator):\n",
        "        # Trích xuất dữ liệu từ batch\n",
        "        src, src_lens = batch.text  # Văn bản đầu vào và độ dài của nó\n",
        "        trg, _ = batch.slot  # Chuỗi đích (slot)\n",
        "        label = batch.intent  # Nhãn intent\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Chạy mô hình để nhận dự đoán\n",
        "        slot_outputs, intent_outputs = model(src, src_lens)\n",
        "\n",
        "        # Reshape đầu ra và nhãn để tính toán lỗi\n",
        "        output_dim = slot_outputs.shape[-1]\n",
        "        slot_outputs = slot_outputs[:, 1:, :].reshape(-1, output_dim)\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        # Tính lỗi cho từng phần của mô hình (slot và intent)\n",
        "        loss1 = loss_slot(slot_outputs, trg)  # Lỗi cho slot\n",
        "        loss2 = loss_intent(intent_outputs, label)  # Lỗi cho intent\n",
        "        loss = loss1 + loss2  # Tổng lỗi\n",
        "\n",
        "        # Lan truyền ngược và cập nhật trọng số\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # Ngăn chặn giá trị gradient quá lớn\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Cập nhật tổng lỗi\n",
        "        epoch_loss += float(loss.item())\n",
        "        slot_epoch_loss += float(loss1.item())\n",
        "        intent_epoch_loss += float(loss2.item())\n",
        "\n",
        "    # Tính lỗi trung bình cho mỗi batch và trả về\n",
        "    num_batches = len(iterator)\n",
        "    return epoch_loss / num_batches, slot_epoch_loss / num_batches, intent_epoch_loss / num_batches\n"
      ],
      "metadata": {
        "id": "2CdT_NPLztwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, loss_slot, loss_intent):\n",
        "    # Chuyển mô hình sang chế độ đánh giá\n",
        "    model.eval()\n",
        "\n",
        "    # Khởi tạo các biến tổng lỗi\n",
        "    epoch_loss = 0\n",
        "    slot_epoch_loss = 0\n",
        "    intent_epoch_loss = 0\n",
        "\n",
        "    # Tính toán lỗi trên tập validation/test\n",
        "    with torch.no_grad():\n",
        "        # Lặp qua từng batch trong iterator\n",
        "        for i, batch in enumerate(iterator):\n",
        "            # Trích xuất dữ liệu từ batch\n",
        "            src, src_len = batch.text  # Văn bản đầu vào và độ dài của nó\n",
        "            trg, _ = batch.slot  # Chuỗi đích (slot)\n",
        "            label = batch.intent  # Nhãn intent\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            # Chạy mô hình để nhận dự đoán\n",
        "            slot_outputs, intent_outputs = model(src, src_len)\n",
        "\n",
        "            # Reshape đầu ra và nhãn để tính toán lỗi\n",
        "            output_dim = slot_outputs.shape[-1]\n",
        "            slot_outputs = slot_outputs[:, 1:, :].reshape(-1, output_dim)\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            # Tính lỗi cho từng phần của mô hình (slot và intent)\n",
        "            loss1 = loss_slot(slot_outputs, trg)  # Lỗi cho slot\n",
        "            loss2 = loss_intent(intent_outputs, label)  # Lỗi cho intent\n",
        "            loss = loss1 + loss2  # Tổng hợp lỗi\n",
        "\n",
        "            # Cập nhật tổng lỗi\n",
        "            epoch_loss += float(loss.item())\n",
        "            slot_epoch_loss += float(loss1.item())\n",
        "            intent_epoch_loss += float(loss2.item())\n",
        "\n",
        "    # Tính lỗi trung bình cho mỗi batch và trả về\n",
        "    num_batches = len(iterator)\n",
        "    return epoch_loss / num_batches, slot_epoch_loss / num_batches, intent_epoch_loss / num_batches\n"
      ],
      "metadata": {
        "id": "Umug5ccyz0ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_iterator, val_iterator, optimizer, scheduler, loss_slot, loss_intent, n_epochs, clip, model_path, writer):\n",
        "    # Khởi tạo biến lưu trữ lỗi tốt nhất trên tập validation\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    # Lặp qua số epoch đã định trước\n",
        "    for epoch in range(n_epochs):\n",
        "        # Bắt đầu tính thời gian để đoạn mã chạy mỗi epoch\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Huấn luyện mô hình trên tập huấn luyện\n",
        "        train_loss, train_slot_loss, train_intent_loss = train(model, train_iterator, optimizer, loss_slot, loss_intent, clip)\n",
        "\n",
        "        # Ghi lỗi huấn luyện vào tensorboard\n",
        "        writer.add_scalar('loss', train_loss, global_step=epoch+1)\n",
        "        writer.add_scalar('slot_loss', train_slot_loss, global_step=epoch+1)\n",
        "        writer.add_scalar('intent_loss', train_intent_loss, global_step=epoch+1)\n",
        "\n",
        "        # Đánh giá mô hình trên tập validation\n",
        "        valid_loss, valid_slot_loss, valid_intent_loss = evaluate(model, val_iterator, loss_slot, loss_intent)\n",
        "\n",
        "        # Kết thúc tính thời gian cho epoch hiện tại\n",
        "        end_time = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        # Lưu mô hình nếu lỗi trên tập validation tốt hơn lỗi tốt nhất trước đó\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        # Điều chỉnh learning rate dựa trên lỗi tập validation\n",
        "        scheduler.step(valid_loss)\n",
        "\n",
        "        # In thông tin về quá trình huấn luyện và đánh giá\n",
        "        print(f'epoch: {epoch + 1}, time-mins: {epoch_mins}, time-secs: {epoch_secs}')\n",
        "        print(f'train loss: {train_loss}, train perplexity: {math.exp(train_loss)}')\n",
        "        print(f'train slot loss: {train_slot_loss}, train slot perplexity: {math.exp(train_slot_loss)}')\n",
        "        print(f'train intent loss: {train_intent_loss}, train intent perplexity: {math.exp(train_intent_loss)}')\n",
        "        print(f'val loss: {valid_loss}, val perplexity: {math.exp(valid_loss)}')\n",
        "        print(f'val slot loss: {valid_slot_loss}, val slot perplexity: {math.exp(valid_slot_loss)}')\n",
        "        print(f'val intent loss: {valid_intent_loss}, val intent perplexity: {math.exp(valid_intent_loss)}')\n",
        "\n",
        "    # Đóng writer TensorBoard\n",
        "    writer.flush()\n",
        "    writer.close()\n"
      ],
      "metadata": {
        "id": "KpBMyOP9z5pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    # Tính thời gian chạy của một epoch\n",
        "    run_tim = end_time - start_time\n",
        "    # Chuyển đổi thời gian chạy thành phút và giây\n",
        "    run_mins = int(run_tim / 60)\n",
        "    run_secs = int(run_tim - (run_mins * 60))\n",
        "    # Trả về thời gian chạy trong định dạng (phút, giây)\n",
        "    return run_mins, run_secs\n",
        "\n",
        "def init_weights(model):\n",
        "    # Khởi tạo trọng số của mô hình với giá trị ngẫu nhiên trong khoảng [-0.5, 0.5]\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.5, 0.5)\n"
      ],
      "metadata": {
        "id": "HgW1Q6fc0F2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo đối tượng SummaryWriter để ghi log cho TensorBoard\n",
        "writer = SummaryWriter(os.getcwd()+'/log', comment='intent_slot')\n",
        "\n",
        "# Các tham số của mô hình và quá trình huấn luyện\n",
        "text_emb_dim = 64\n",
        "hidden_dim = 128\n",
        "n_layers = 2\n",
        "dropout = 0.2\n",
        "lr = 0.005\n",
        "gamma = 0.2\n",
        "weight_decay = 0.2\n",
        "n_epochs = 20\n",
        "clip = 5.0\n",
        "seq_len = 50\n",
        "\n",
        "# Đường dẫn lưu trữ trọng số của mô hình\n",
        "model_path = os.path.join(os.getcwd(), \"model.h5\")\n",
        "\n",
        "# Xây dựng mô hình, tạo optimizer, scheduler và các hàm mất mát\n",
        "model, optimizer, scheduler, loss_slot, loss_intent = build_model(TEXT,\n",
        "                                                                  SLOT,\n",
        "                                                                  INTENT,\n",
        "                                                                  text_emb_dim,\n",
        "                                                                  hidden_dim,\n",
        "                                                                  n_layers,\n",
        "                                                                  dropout,\n",
        "                                                                  lr,\n",
        "                                                                  gamma,\n",
        "                                                                  weight_decay,\n",
        "                                                                  seq_len)\n",
        "\n",
        "# Không cần thiết lập AMP (Automatic Mixed Precision) vì đây là mã CPU\n",
        "\n",
        "# Huấn luyện mô hình trên tập huấn luyện và đánh giá trên tập validation\n",
        "train_model(model,\n",
        "            train_iter,\n",
        "            val_iter,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            loss_slot,\n",
        "            loss_intent,\n",
        "            n_epochs,\n",
        "            clip,\n",
        "            model_path,\n",
        "            writer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hslc1Rw0Igh",
        "outputId": "29e138bc-795c-4c38-9a6e-15501099d46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, time-mins: 0, time-secs: 7\n",
            "train loss: 10.174558579266726, train perplexity: 26227.364185467773\n",
            "train slot loss: 7.514621226669668, train slot perplexity: 1834.6724196850823\n",
            "train intent loss: 2.659937266465072, train intent perplexity: 14.295392270056997\n",
            "val loss: 2.888974905014038, val perplexity: 17.974874200729737\n",
            "val slot loss: 0.23419204354286194, val slot perplexity: 1.2638871902765318\n",
            "val intent loss: 2.654782772064209, val intent perplexity: 14.221896330572044\n",
            "epoch: 2, time-mins: 0, time-secs: 7\n",
            "train loss: 2.574801434527387, train perplexity: 13.12870999114768\n",
            "train slot loss: 0.1594017527096874, train slot perplexity: 1.172809031250881\n",
            "train intent loss: 2.4153996797708364, train intent perplexity: 11.194243576272893\n",
            "val loss: 2.412687301635742, val perplexity: 11.163921695550659\n",
            "val slot loss: 0.057294368743896484, val slot perplexity: 1.0589674914489544\n",
            "val intent loss: 2.3553929328918457, val intent perplexity: 10.542270452774137\n",
            "epoch: 3, time-mins: 0, time-secs: 8\n",
            "train loss: 2.5886783337855075, train perplexity: 13.31216573152664\n",
            "train slot loss: 0.19775846326252916, train slot perplexity: 1.218668005176207\n",
            "train intent loss: 2.390919879242614, train intent perplexity: 10.92353765837897\n",
            "val loss: 2.4197545051574707, val perplexity: 11.24309885327364\n",
            "val slot loss: 0.06927824765443802, val slot perplexity: 1.071734375240506\n",
            "val intent loss: 2.3504762649536133, val intent perplexity: 10.490564823506956\n",
            "epoch: 4, time-mins: 0, time-secs: 7\n",
            "train loss: 2.4560893027337043, train perplexity: 11.65912695300693\n",
            "train slot loss: 0.06646571850793047, train slot perplexity: 1.068724325982667\n",
            "train intent loss: 2.3896235869481015, train intent perplexity: 10.909386734531937\n",
            "val loss: 2.498328685760498, val perplexity: 12.162150190226452\n",
            "val slot loss: 0.02113223820924759, val slot perplexity: 1.0213571051423014\n",
            "val intent loss: 2.477196455001831, val intent perplexity: 11.907833430254573\n",
            "epoch: 5, time-mins: 0, time-secs: 7\n",
            "train loss: 2.40783437529763, train perplexity: 11.109875253688426\n",
            "train slot loss: 0.03667026036674832, train slot perplexity: 1.0373509087290986\n",
            "train intent loss: 2.3711641201606164, train intent perplexity: 10.709852585371802\n",
            "val loss: 2.392503261566162, val perplexity: 10.940847495246262\n",
            "val slot loss: 0.014406373724341393, val slot perplexity: 1.0145106456513524\n",
            "val intent loss: 2.37809681892395, val intent perplexity: 10.784358733073676\n",
            "epoch: 6, time-mins: 0, time-secs: 7\n",
            "train loss: 2.394695672360095, train perplexity: 10.964860641111116\n",
            "train slot loss: 0.022511633908744534, train slot perplexity: 1.0227669328723956\n",
            "train intent loss: 2.3721840460221846, train intent perplexity: 10.720781413346959\n",
            "val loss: 2.313363790512085, val perplexity: 10.108369969538458\n",
            "val slot loss: 0.008932539261877537, val slot perplexity: 1.0089725534447231\n",
            "val intent loss: 2.304431200027466, val intent perplexity: 10.018478121381166\n",
            "epoch: 7, time-mins: 0, time-secs: 7\n",
            "train loss: 2.4098340233603674, train perplexity: 11.132113320960707\n",
            "train slot loss: 0.015573826092704721, train slot perplexity: 1.0156957301375926\n",
            "train intent loss: 2.394260191655421, train intent perplexity: 10.96008669542853\n",
            "val loss: 2.4798285961151123, val perplexity: 11.939217814140337\n",
            "val slot loss: 0.006459563970565796, val slot perplexity: 1.0064804719484737\n",
            "val intent loss: 2.4733691215515137, val intent perplexity: 11.862345285722405\n",
            "epoch: 8, time-mins: 0, time-secs: 10\n",
            "train loss: 2.3930770669664656, train perplexity: 10.94712721411893\n",
            "train slot loss: 0.014144626532420311, train slot perplexity: 1.0142451350885173\n",
            "train intent loss: 2.378932447223873, train intent perplexity: 10.793374214698735\n",
            "val loss: 2.350558042526245, val perplexity: 10.491422751512916\n",
            "val slot loss: 0.007419147994369268, val slot perplexity: 1.0074467380622434\n",
            "val intent loss: 2.3431389331817627, val intent perplexity: 10.413873766850223\n",
            "epoch: 9, time-mins: 0, time-secs: 7\n",
            "train loss: 2.394173624751332, train perplexity: 10.959137955720081\n",
            "train slot loss: 0.012945305753709073, train slot perplexity: 1.0130294589618343\n",
            "train intent loss: 2.3812283212011986, train intent perplexity: 10.818182909607032\n",
            "val loss: 2.4583258628845215, val perplexity: 11.685232474145403\n",
            "val slot loss: 0.004882320761680603, val slot perplexity: 1.004894258710081\n",
            "val intent loss: 2.4534435272216797, val intent perplexity: 11.62832029214841\n",
            "epoch: 10, time-mins: 0, time-secs: 7\n",
            "train loss: 2.282315018412831, train perplexity: 9.799339823053193\n",
            "train slot loss: 0.005498649003969219, train slot perplexity: 1.0055137943212735\n",
            "train intent loss: 2.2768163733429962, train intent perplexity: 9.745604602291621\n",
            "val loss: 2.2421987056732178, val perplexity: 9.41400718000657\n",
            "val slot loss: 0.00035964016569778323, val slot perplexity: 1.0003597048439756\n",
            "val intent loss: 2.2418391704559326, val intent perplexity: 9.410623121270183\n",
            "epoch: 11, time-mins: 0, time-secs: 7\n",
            "train loss: 2.260766571694678, train perplexity: 9.590438108052512\n",
            "train slot loss: 0.003031326017222894, train slot perplexity: 1.0030359251318988\n",
            "train intent loss: 2.257735239280449, train intent perplexity: 9.561410320813067\n",
            "val loss: 2.2475666999816895, val perplexity: 9.464677394005609\n",
            "val slot loss: 0.00018767156871035695, val slot perplexity: 1.000187689180121\n",
            "val intent loss: 2.2473790645599365, val intent perplexity: 9.462901651872302\n",
            "epoch: 12, time-mins: 0, time-secs: 7\n",
            "train loss: 2.250848371903975, train perplexity: 9.495788380167417\n",
            "train slot loss: 0.002273645449309737, train slot perplexity: 1.0022762321411596\n",
            "train intent loss: 2.248574733734131, train intent perplexity: 9.474222918571916\n",
            "val loss: 2.239950656890869, val perplexity: 9.392867802706947\n",
            "val slot loss: 0.00010039143671747297, val slot perplexity: 1.0001003964761064\n",
            "val intent loss: 2.2398502826690674, val intent perplexity: 9.391925048225678\n",
            "epoch: 13, time-mins: 0, time-secs: 7\n",
            "train loss: 2.255919241643214, train perplexity: 9.544062578758643\n",
            "train slot loss: 0.002068974338116887, train slot perplexity: 1.0020711161423808\n",
            "train intent loss: 2.2538502583136926, train intent perplexity: 9.524336485902698\n",
            "val loss: 2.2400221824645996, val perplexity: 9.393539656992605\n",
            "val slot loss: 0.00013684039004147053, val slot perplexity: 1.0001368497531147\n",
            "val intent loss: 2.2398853302001953, val intent perplexity: 9.392254217779413\n",
            "epoch: 14, time-mins: 0, time-secs: 8\n",
            "train loss: 2.253434024014316, train perplexity: 9.520372955314372\n",
            "train slot loss: 0.0018649846885767016, train slot perplexity: 1.0018667248541469\n",
            "train intent loss: 2.2515690379090363, train intent perplexity: 9.502634138500628\n",
            "val loss: 2.2449569702148438, val perplexity: 9.440009346146807\n",
            "val slot loss: 8.786114631220698e-05, val slot perplexity: 1.0000878650062157\n",
            "val intent loss: 2.2448689937591553, val intent perplexity: 9.439178884113955\n",
            "epoch: 15, time-mins: 0, time-secs: 7\n",
            "train loss: 2.2542182691804658, train perplexity: 9.527842190257399\n",
            "train slot loss: 0.001364275441409228, train slot perplexity: 1.0013652064885026\n",
            "train intent loss: 2.2528539909111274, train intent perplexity: 9.514852425045518\n",
            "val loss: 2.235734701156616, val perplexity: 9.353351246390664\n",
            "val slot loss: 6.883704918436706e-05, val slot perplexity: 1.0000688394185084\n",
            "val intent loss: 2.235665798187256, val intent perplexity: 9.352706794918882\n",
            "epoch: 16, time-mins: 0, time-secs: 7\n",
            "train loss: 2.259287496189495, train perplexity: 9.576263611122606\n",
            "train slot loss: 0.0010012696967640915, train slot perplexity: 1.001001771134611\n",
            "train intent loss: 2.2582862219967685, train intent perplexity: 9.566679944245877\n",
            "val loss: 2.2507193088531494, val perplexity: 9.494562903832636\n",
            "val slot loss: 3.9795355405658484e-05, val slot perplexity: 1.0000397961472514\n",
            "val intent loss: 2.2506794929504395, val intent perplexity: 9.494184876765578\n",
            "epoch: 17, time-mins: 0, time-secs: 7\n",
            "train loss: 2.2549441437144857, train perplexity: 9.534760718955587\n",
            "train slot loss: 0.0015145930401134107, train slot perplexity: 1.0015157406154487\n",
            "train intent loss: 2.2534295438410163, train intent perplexity: 9.520330302489203\n",
            "val loss: 2.2467799186706543, val perplexity: 9.457233691384069\n",
            "val slot loss: 5.1441464165691286e-05, val slot perplexity: 1.0000514427873004\n",
            "val intent loss: 2.2467284202575684, val intent perplexity: 9.456746671397266\n",
            "epoch: 18, time-mins: 0, time-secs: 7\n",
            "train loss: 2.261678179541787, train perplexity: 9.599184812865667\n",
            "train slot loss: 0.0015930249556371924, train slot perplexity: 1.0015942944939378\n",
            "train intent loss: 2.2600851478157464, train intent perplexity: 9.583905180615437\n",
            "val loss: 2.2435414791107178, val perplexity: 9.42665654950639\n",
            "val slot loss: 3.263855978730135e-05, val slot perplexity: 1.0000326390924308\n",
            "val intent loss: 2.243508815765381, val intent perplexity: 9.426348648396708\n",
            "epoch: 19, time-mins: 0, time-secs: 7\n",
            "train loss: 2.2430636699383077, train perplexity: 9.422153482430923\n",
            "train slot loss: 0.0011902834300829225, train slot perplexity: 1.0011909920985491\n",
            "train intent loss: 2.2418733953119636, train intent perplexity: 9.410945204003255\n",
            "val loss: 2.231975793838501, val perplexity: 9.318258861771854\n",
            "val slot loss: 1.910876017063856e-05, val slot perplexity: 1.0000191089427442\n",
            "val intent loss: 2.231956720352173, val intent perplexity: 9.318081131783822\n",
            "epoch: 20, time-mins: 0, time-secs: 7\n",
            "train loss: 2.2392785182366004, train perplexity: 9.386556614416714\n",
            "train slot loss: 0.0006819045627478093, train slot perplexity: 1.00068213711252\n",
            "train intent loss: 2.2385966149005263, train intent perplexity: 9.380158071988747\n",
            "val loss: 2.2314951419830322, val perplexity: 9.313781099568766\n",
            "val slot loss: 1.4350081073644105e-05, val slot perplexity: 1.0000143501840366\n",
            "val intent loss: 2.231480836868286, val intent perplexity: 9.313647865814382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_words_path = os.path.join(os.getcwd(), 'text_words.pkl')\n",
        "with open(text_words_path, 'rb') as f_text_words:\n",
        "    text_words = pickle.load(f_text_words)\n",
        "\n",
        "slot_words_path = os.path.join(os.getcwd(), 'slot_words.pkl')\n",
        "with open(slot_words_path, 'rb') as f_slot_words:\n",
        "    slot_words = pickle.load(f_slot_words)\n",
        "\n",
        "\n",
        "intent_words_path = os.path.join(os.getcwd(), 'intent_words.pkl')\n",
        "with open(intent_words_path, 'rb') as f_intent_words:\n",
        "    intent_words = pickle.load(f_intent_words)"
      ],
      "metadata": {
        "id": "Dz_XcDV947K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_slot_loss, test_intent_loss = evaluate(model, test_iter, loss_slot, loss_intent)\n",
        "\n",
        "# Calculate perplexity\n",
        "test_perplexity = math.exp(test_loss)\n",
        "test_slot_perplexity = math.exp(test_slot_loss)\n",
        "test_intent_perplexity = math.exp(test_intent_loss)\n",
        "\n",
        "# Print or log the test evaluation results\n",
        "print(f'Test loss: {test_loss}, Test perplexity: {test_perplexity}')\n",
        "print(f'Test slot loss: {test_slot_loss}, Test slot perplexity: {test_slot_perplexity}')\n",
        "print(f'Test intent loss: {test_intent_loss}, Test intent perplexity: {test_intent_perplexity}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onpt2Lib5hbQ",
        "outputId": "30ece04a-48c1-47de-f3f4-d379a7f75270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2.239734172821045, Test perplexity: 9.390834616541845\n",
            "Test slot loss: 0.004253751132637262, Test slot perplexity: 1.004262811173818\n",
            "Test intent loss: 2.235480308532715, Test intent perplexity: 9.350972125453064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Các thông số của mô hình\n",
        "text_emb_dim = 64\n",
        "hidden_dim = 128\n",
        "n_layers = 2\n",
        "dropout = 0.2\n",
        "seq_len = 50\n",
        "\n",
        "# Đường dẫn lưu trữ trọng số của mô hình\n",
        "model_path = os.path.join(os.getcwd(), \"model.h5\")\n",
        "\n",
        "# Số lượng từ trong từ điển của dữ liệu\n",
        "input_dim = len(text_words)\n",
        "output_dim = len(slot_words)\n",
        "label_dim = len(intent_words)\n",
        "\n",
        "# Khởi tạo mô hình\n",
        "model = BirnnAttentionGate(input_dim, text_emb_dim, hidden_dim, n_layers, dropout, text_words['<pad>'], output_dim, label_dim, seq_len, True, True)\n",
        "\n",
        "# Nạp trọng số đã được lưu\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# Chuyển mô hình về chế độ đánh giá\n",
        "model.eval()\n",
        "\n",
        "# Chuỗi đầu vào để dự đoán\n",
        "sentence = \"bật tv 4 ở 53 phần trăm\"\n",
        "\n",
        "# Dự đoán với đầu vào mới\n",
        "with torch.no_grad():\n",
        "    # Tokenize câu và thêm token kết thúc ('<eos>')\n",
        "    tokenized = sentence.split()\n",
        "    tokenized.append('<eos>')\n",
        "    indexed = [text_words[t] for t in tokenized]\n",
        "\n",
        "    # Chuyển đổi thành dạng Tensor\n",
        "    tensor = torch.LongTensor(indexed)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "\n",
        "    # Dự đoán intent và slot\n",
        "    slot_outputs, intent_outputs = model(tensor, [len(tensor[0])])\n",
        "    intent = torch.argmax(intent_outputs, dim=1).item()\n",
        "    slot_indices = torch.argmax(slot_outputs, dim=2)\n",
        "\n",
        "    # Chuyển đổi các index slot thành chuỗi dự đoán, chú ý capitalize và thay thế token không mong muốn\n",
        "    slot_prediction = [slot_words.itos[idx.item()].capitalize() if slot_words.itos[idx.item()] not in ['<eos>', '<sos>', '<unk>', '<pad>'] else 'O' for idx in slot_indices[0]]\n",
        "\n",
        "    # In kết quả dự đoán\n",
        "    print('slot_prediciton: {}'.format(' '.join(slot_prediction)))\n",
        "    print('intent_prediction: {}'.format(intent_words.itos[intent]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo_l1CNW5Nxw",
        "outputId": "73a6d102-ca5e-4a85-b4a8-370aef55182a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "slot_prediciton: B-commandcommand B-devicedevice I-devicedevice O B-final-valuesyspercentage I-final-valuesyspercentage I-final-valuesyspercentage O\n",
            "intent_prediction: smart.home.increase.level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nạp trọng số của mô hình đã được huấn luyện\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "# Đường dẫn đến file đầu vào chứa nhiều câu\n",
        "input_file_path = \"seq.in\"\n",
        "# Đường dẫn đến file kết quả đầu ra\n",
        "output_file_path = \"output_results.csv\"\n",
        "\n",
        "# Mở file đầu vào và file đầu ra để ghi kết quả\n",
        "with open(input_file_path, 'r') as input_file, open(output_file_path, 'w', newline='') as output_file:\n",
        "    # Sử dụng csv writer để viết vào file kết quả\n",
        "    csv_writer = csv.writer(output_file)\n",
        "    # Ghi dòng tiêu đề của file kết quả\n",
        "    csv_writer.writerow([\"text\", \"slot\", \"intent\"])\n",
        "\n",
        "    # Đọc từng câu từ file đầu vào\n",
        "    for sentence in input_file.readlines():\n",
        "        sentence = sentence.strip()\n",
        "\n",
        "        # Dự đoán với mỗi câu\n",
        "        with torch.no_grad():\n",
        "            # Tokenize câu và thêm token kết thúc ('<eos>')\n",
        "            tokenized = sentence.split()\n",
        "            tokenized.append('<eos>')\n",
        "            # Chuyển các từ thành index, sử dụng <unk> nếu từ không có trong từ điển\n",
        "            indexed = [text_words.stoi[t] if t in text_words.stoi else text_words.stoi['<unk>'] for t in tokenized]\n",
        "            tensor = torch.LongTensor(indexed)\n",
        "            tensor = tensor.unsqueeze(0)\n",
        "\n",
        "            # Dự đoán intent và slot\n",
        "            slot_outputs, intent_outputs = model(tensor, [len(tensor[0])])\n",
        "            intent = torch.argmax(intent_outputs, dim=1).item()\n",
        "            slot_indices = torch.argmax(slot_outputs, dim=2)\n",
        "            # Chuyển đổi các index slot thành chuỗi dự đoán, chú ý capitalize và thay thế token không mong muốn\n",
        "            slot_prediction = [slot_words.itos[idx.item()].capitalize() if slot_words.itos[idx.item()] not in ['<eos>', '<sos>', '<unk>', '<pad>'] else 'O' for idx in slot_indices[0]]\n",
        "\n",
        "            # Ghi kết quả vào file kết quả\n",
        "            csv_writer.writerow([sentence, ' '.join(slot_prediction), intent_words.itos[intent]])\n",
        "\n",
        "print(f\"Results saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOFClMVn7yCa",
        "outputId": "2db01828-03ac-4d0d-ee7e-a489e1bb946c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to output_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"output_results.csv\")\n",
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4zbXiTtD70Ww",
        "outputId": "fd436c48-4534-45b7-8098-e206b0bdb10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  \\\n",
              "0    tăng giúp mình mức độ của ốp tường thứ 1 lên với   \n",
              "1                     tôi muốn tăng đèn sắc màu thứ 3   \n",
              "2                            tôi muốn tăng đèn cảnh 3   \n",
              "3   chòa bạn tôi muốn tăng mức độ của bóng ốp trần...   \n",
              "4   giúp mình tăng đèn vườn thứ 1 lên 2 phần trăm ...   \n",
              "5             tăng hộ mình điện 4 lên 9 phần trăm nhé   \n",
              "6   chào bạn bạn tăng giúp mình bòng hắt trần thứ ...   \n",
              "7                     tăng tv lên 11 phần trăm bạn ơi   \n",
              "8     tăng hộ mình bóng làm việc lên 11 phần trăm nhé   \n",
              "9   giúp mình tăng quạt thông gió 3 lên 5 phần tră...   \n",
              "10  chào bạn bạn tăng giúp mình flash 4 lên 14 phầ...   \n",
              "11  giúp mình tăng nóng lạnh thứ 4 lên 3 phần trăm...   \n",
              "12  bạn ơi chỗ mình tối quá giúp mình tăng đèn hắt...   \n",
              "13  giúp mình tăng đèn bếp thứ 2 lên 11 phần trăm ...   \n",
              "14  chào bạn bạn tăng giúp mình cột đèn lên 24 phầ...   \n",
              "15                       tôi muốn tăng bóng âm trần 2   \n",
              "16                          tôi muốn tăng flash thứ 3   \n",
              "17  chào bạn bạn tăng giúp mình quạt hút mùi thứ 3...   \n",
              "18          tăng nút ấn thứ 4 lên 20 phần trăm bạn ơi   \n",
              "19  bạn ơi chỗ mình tối quá giúp mình tăng đèn dow...   \n",
              "\n",
              "                                                 slot  \\\n",
              "0   O O O O O O B-devicedevice I-devicedevice I-de...   \n",
              "1   O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "2   O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "3   O O O O O O O O B-devicedevice I-devicedevice ...   \n",
              "4   O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "5   O I-final-valuesyspercentage O B-devicedevice ...   \n",
              "6   O O O O O O B-devicedevice I-devicedevice I-de...   \n",
              "7   O B-devicedevice O I-devicedevice I-roomroom I...   \n",
              "8   O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "9   O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "10  O O O O O O B-devicedevice I-devicedevice O B-...   \n",
              "11  O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "12  O O O O O O O O O B-devicedevice I-devicedevic...   \n",
              "13  O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "14  O O O O O O B-devicedevice I-devicedevice O B-...   \n",
              "15  O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "16  O O O B-devicedevice I-devicedevice I-devicede...   \n",
              "17  O O O O O O B-devicedevice I-devicedevice I-de...   \n",
              "18  O B-devicedevice I-devicedevice I-devicedevice...   \n",
              "19  O O O O O O O O O B-devicedevice I-devicedevic...   \n",
              "\n",
              "                       intent  \n",
              "0   smart.home.increase.level  \n",
              "1   smart.home.increase.level  \n",
              "2   smart.home.increase.level  \n",
              "3   smart.home.increase.level  \n",
              "4   smart.home.increase.level  \n",
              "5   smart.home.increase.level  \n",
              "6   smart.home.increase.level  \n",
              "7   smart.home.increase.level  \n",
              "8   smart.home.increase.level  \n",
              "9   smart.home.increase.level  \n",
              "10  smart.home.increase.level  \n",
              "11  smart.home.increase.level  \n",
              "12  smart.home.increase.level  \n",
              "13  smart.home.increase.level  \n",
              "14  smart.home.increase.level  \n",
              "15  smart.home.increase.level  \n",
              "16  smart.home.increase.level  \n",
              "17  smart.home.increase.level  \n",
              "18  smart.home.increase.level  \n",
              "19  smart.home.increase.level  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cadc785-6c26-4d69-914e-012e179eaaa6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>slot</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tăng giúp mình mức độ của ốp tường thứ 1 lên với</td>\n",
              "      <td>O O O O O O B-devicedevice I-devicedevice I-de...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tôi muốn tăng đèn sắc màu thứ 3</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tôi muốn tăng đèn cảnh 3</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chòa bạn tôi muốn tăng mức độ của bóng ốp trần...</td>\n",
              "      <td>O O O O O O O O B-devicedevice I-devicedevice ...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>giúp mình tăng đèn vườn thứ 1 lên 2 phần trăm ...</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tăng hộ mình điện 4 lên 9 phần trăm nhé</td>\n",
              "      <td>O I-final-valuesyspercentage O B-devicedevice ...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>chào bạn bạn tăng giúp mình bòng hắt trần thứ ...</td>\n",
              "      <td>O O O O O O B-devicedevice I-devicedevice I-de...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tăng tv lên 11 phần trăm bạn ơi</td>\n",
              "      <td>O B-devicedevice O I-devicedevice I-roomroom I...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tăng hộ mình bóng làm việc lên 11 phần trăm nhé</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>giúp mình tăng quạt thông gió 3 lên 5 phần tră...</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>chào bạn bạn tăng giúp mình flash 4 lên 14 phầ...</td>\n",
              "      <td>O O O O O O B-devicedevice I-devicedevice O B-...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>giúp mình tăng nóng lạnh thứ 4 lên 3 phần trăm...</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bạn ơi chỗ mình tối quá giúp mình tăng đèn hắt...</td>\n",
              "      <td>O O O O O O O O O B-devicedevice I-devicedevic...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>giúp mình tăng đèn bếp thứ 2 lên 11 phần trăm ...</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>chào bạn bạn tăng giúp mình cột đèn lên 24 phầ...</td>\n",
              "      <td>O O O O O O B-devicedevice I-devicedevice O B-...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>tôi muốn tăng bóng âm trần 2</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tôi muốn tăng flash thứ 3</td>\n",
              "      <td>O O O B-devicedevice I-devicedevice I-devicede...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>chào bạn bạn tăng giúp mình quạt hút mùi thứ 3...</td>\n",
              "      <td>O O O O O O B-devicedevice I-devicedevice I-de...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>tăng nút ấn thứ 4 lên 20 phần trăm bạn ơi</td>\n",
              "      <td>O B-devicedevice I-devicedevice I-devicedevice...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>bạn ơi chỗ mình tối quá giúp mình tăng đèn dow...</td>\n",
              "      <td>O O O O O O O O O B-devicedevice I-devicedevic...</td>\n",
              "      <td>smart.home.increase.level</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cadc785-6c26-4d69-914e-012e179eaaa6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1cadc785-6c26-4d69-914e-012e179eaaa6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1cadc785-6c26-4d69-914e-012e179eaaa6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35beec81-f2a4-4869-bebb-949d515a71bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35beec81-f2a4-4869-bebb-949d515a71bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35beec81-f2a4-4869-bebb-949d515a71bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}